{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy/RAfrYwaxNEydZjnAtCs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricCostaDev/tcc-codes/blob/main/TCC_CNN_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VGG16**"
      ],
      "metadata": {
        "id": "mXuna4n-Hk9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO-DO:\n",
        "Add the optmization part"
      ],
      "metadata": {
        "id": "foz6DvOEHw_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbDKTi8RY6ia"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "BZeYZZWFyUv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c 'state-farm-distracted-driver-detection'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zowsCKSkzA6E",
        "outputId": "bfdbf9a8-8d29-4384-897e-def53f0ff5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading state-farm-distracted-driver-detection.zip to /content\n",
            "100% 4.00G/4.00G [00:37<00:00, 123MB/s]\n",
            "100% 4.00G/4.00G [00:37<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir state-farm-distracted-driver-detection\n",
        "! unzip state-farm-distracted-driver-detection.zip -d state-farm-distracted-driver-detection"
      ],
      "metadata": {
        "id": "shOh7gG-0Z5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AFXGT-8h1mb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_details = pd.read_csv('/content/state-farm-distracted-driver-detection/driver_imgs_list.csv',na_values='na')\n",
        "print(driver_details.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBemLYYx1lth",
        "outputId": "13ff7549-2b6b-4075-8998-c80077c30cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  subject classname            img\n",
            "0    p002        c0  img_44733.jpg\n",
            "1    p002        c0  img_72999.jpg\n",
            "2    p002        c0  img_25094.jpg\n",
            "3    p002        c0  img_69092.jpg\n",
            "4    p002        c0  img_92629.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "wpcOJb4M2o3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET (usar o do kaggle ou o BROOK)\n",
        "\n",
        "train_image = []\n",
        "image_label = []\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('now we are in the folder C',i)\n",
        "    imgs = os.listdir(\"/content/state-farm-distracted-driver-detection/imgs/train/c\"+str(i))\n",
        "    for j in range(len(imgs)):\n",
        "    #for j in range(100):\n",
        "        img_name = \"/content/state-farm-distracted-driver-detection/imgs/train/c\"+str(i)+\"/\"+imgs[j]\n",
        "        img = cv2.imread(img_name)\n",
        "        #img = color.rgb2gray(img)\n",
        "        img = img[50:,120:-50]\n",
        "        img = cv2.resize(img,(224,224))\n",
        "        label = i\n",
        "        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n",
        "        train_image.append([img,label,driver])\n",
        "        image_label.append(i)\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWqcpkb4xs_J",
        "outputId": "1f84734f-9e01-4610-b00f-61da27fd4b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now we are in the folder C 0\n",
            "now we are in the folder C 1\n",
            "now we are in the folder C 2\n",
            "now we are in the folder C 3\n",
            "now we are in the folder C 4\n",
            "now we are in the folder C 5\n",
            "now we are in the folder C 6\n",
            "now we are in the folder C 7\n",
            "now we are in the folder C 8\n",
            "now we are in the folder C 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Randomly shuffling the images\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(train_image)"
      ],
      "metadata": {
        "id": "-M3vLUUsj_jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driv_selected = ['p050', 'p015', 'p022', 'p056']"
      ],
      "metadata": {
        "id": "zpDHCD_KkKY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## getting list of driver names\n",
        "\n",
        "D = []\n",
        "for features,labels,drivers in train_image:\n",
        "    D.append(drivers)\n",
        "\n",
        "## Deduplicating drivers\n",
        "\n",
        "deduped = []\n",
        "\n",
        "for i in D:\n",
        "    if i not in deduped:\n",
        "        deduped.append(i)\n",
        "    \n",
        "\n",
        "## selecting random drivers for the validation set\n",
        "driv_selected = []\n",
        "import random\n",
        "driv_nums = random.sample(range(len(deduped)), 4)\n",
        "for i in driv_nums:\n",
        "    driv_selected.append(deduped[i])"
      ],
      "metadata": {
        "id": "EalyhzhYkNVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting the train and test\n",
        "\n",
        "X_train= []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "D_train = []\n",
        "D_test = []\n",
        "\n",
        "for features,labels,drivers in train_image:\n",
        "    if drivers in driv_selected:\n",
        "        X_test.append(features)\n",
        "        y_test.append(labels)\n",
        "        D_test.append(drivers)\n",
        "    \n",
        "    else:\n",
        "        X_train.append(features)\n",
        "        y_train.append(labels)\n",
        "        D_train.append(drivers)\n",
        "    \n",
        "print (len(X_train),len(X_test))\n",
        "print (len(y_train),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IkHRoe_kVui",
        "outputId": "16e0c614-7b1d-4910-d223-bdd828a321fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19209 3215\n",
            "19209 3215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Converting images to nparray. Encoding the Y\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X_train = np.array(X_train).reshape(-1,224,224,3)\n",
        "X_test = np.array(X_test).reshape(-1,224,224,3)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "print (X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpalgNlkZCH",
        "outputId": "2db06e2f-dbd9-4318-ba0a-689c2874eb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19209, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the input\n",
        "\n",
        "from keras.layers import Input\n",
        "vgg16_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
        "\n",
        "\n",
        "## The VGG model\n",
        "\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "#Get back the convolutional part of a VGG network trained on ImageNet\n",
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_tensor = vgg16_input)\n",
        "model_vgg16_conv.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPR7Co_ckpM0",
        "outputId": "aa85f71d-ff73-4bda-d0bf-0ed758a65d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Image_input (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the generated model \n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.layers import Flatten,Dropout\n",
        "\n",
        "output_vgg16_conv = model_vgg16_conv(vgg16_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "\n",
        "x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "# x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "# x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = Dense(10, activation='softmax', name='predictions')(x)\n",
        "\n",
        "vgg16_pretrained = Model(vgg16_input,  x)\n",
        "vgg16_pretrained.summary()\n",
        "\n",
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "vgg16_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4IWLX0dksmk",
        "outputId": "b81caeb0-e08e-42f2-f8fb-bced5fb7adcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Image_input (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                250890    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,965,578\n",
            "Trainable params: 14,965,578\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "checkpointer = ModelCheckpoint('vgg_weights_aug_setval_sgd.hdf5', verbose=1, save_best_only=True)\n",
        "earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    height_shift_range=0.5,\n",
        "    width_shift_range = 0.5,\n",
        "    zoom_range = 0.5,\n",
        "    rotation_range=30\n",
        "        )\n",
        "#datagen.fit(X_train)\n",
        "data_generator = datagen.flow(X_train, y_train, batch_size = 64)\n",
        "\n",
        "# Fits the model on batches with real-time data augmentation:\n",
        "vgg16_model = vgg16_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper],\n",
        "                                                            epochs = 25, verbose = 1, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "id": "l22zlfA4kzcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(vgg16_pretrained.history.history['accuracy']) + 1), vgg16_pretrained.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(vgg16_pretrained.history.history['val_accuracy']) + 1), vgg16_pretrained.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(vgg16_pretrained.history.history['loss']) + 1), vgg16_pretrained.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(vgg16_pretrained.history.history['val_loss']) + 1), vgg16_pretrained.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "metadata": {
        "id": "ghgzccSEk8o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels is the image array\n",
        "test_image = []\n",
        "i = 0\n",
        "fig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n",
        "\n",
        "files = os.listdir('/home/jupyter/TestImages')\n",
        "nums = np.random.randint(low=1, high=len(files), size=20)\n",
        "for i in range(20):\n",
        "    print ('Image number:',i)\n",
        "    img = cv2.imread('/home/jupyter/TestImages/'+files[nums[i]])\n",
        "    #img = color.rgb2gray(img)\n",
        "    img = img[50:,120:-50]\n",
        "    img = cv2.resize(img,(224,224))\n",
        "    test_image.append(img)\n",
        "    ax[i].imshow(img,cmap = 'gray')\n",
        "    plt.show"
      ],
      "metadata": {
        "id": "aPTESB6flBFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = []\n",
        "\n",
        "for img in test_image:\n",
        "    test.append(img)\n",
        "    \n",
        "vgg16_pretrained.load_weights('vgg_weights_aug_setval_sgd.hdf5')\n",
        "\n",
        "\n",
        "test = np.array(test).reshape(-1,224,224,3)\n",
        "prediction = vgg16_pretrained.predict(test)"
      ],
      "metadata": {
        "id": "1KSldFMXlDku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[0]"
      ],
      "metadata": {
        "id": "CWXQUIFOlIwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = { \"C0\": \"safe driving\",\n",
        "\"C1\": \"texting - right\",\n",
        "\"C2\": \"talking on the phone - right\",\n",
        "\"C3\": \"texting - left\",\n",
        "\"C4\": \"talking on the phone - left\",\n",
        "\"C5\": \"operating the radio\",\n",
        "\"C6\": \"drinking\",\n",
        "\"C7\": \"reaching behind\",\n",
        "\"C8\": \"hair and makeup\",\n",
        "\"C9\": \"talking to passenger\" }"
      ],
      "metadata": {
        "id": "7z28HbYAlKXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels is the image array\n",
        "i = 0\n",
        "fig, ax = plt.subplots(20, 1, figsize = (100,100))\n",
        "\n",
        "for i in range(20):\n",
        "    ax[i].imshow(test[i].squeeze())\n",
        "    predicted_class = 'C'+str(np.where(prediction[i] == np.amax(prediction[i]))[0][0])\n",
        "    ax[i].set_title(tags[predicted_class])\n",
        "    plt.show"
      ],
      "metadata": {
        "id": "21NAQZB9lLO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}